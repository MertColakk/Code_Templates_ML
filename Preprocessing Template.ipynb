{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "770176cd",
   "metadata": {},
   "source": [
    "### Preprocessing,Regression,Classification,Clustering... Code Templates by Mustafa Mert Ã‡OLAK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13452b2d",
   "metadata": {},
   "source": [
    "#### Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fce500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead7ad4",
   "metadata": {},
   "source": [
    "#### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7724a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83349fce",
   "metadata": {},
   "source": [
    "#### Spliting Dataset into the x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b4be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ca6875",
   "metadata": {},
   "source": [
    "#### Taking Care With Missing Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca3d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "imputer.fit(x)\n",
    "x = imputer.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c63da8",
   "metadata": {},
   "source": [
    "#### Encoding Datas for X part of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af0dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "col_Transformer = ColumnTransformer([('encoder',OneHotEncoder(),[])],remainder='passthrough')\n",
    "x = np.array(col_Transformer.fit_transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12bcf9d",
   "metadata": {},
   "source": [
    "#### Spliting Dataset into the Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db10182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=1,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd01e81",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d78eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f69629",
   "metadata": {},
   "source": [
    "### Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bcbe36",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de9f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc06dd5",
   "metadata": {},
   "source": [
    "#### Poly. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859cfc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "pol_reg = PolynomialFeatures(degree=4)\n",
    "x_pol = pol_reg.fit_transform(x)\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_pol,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28120f3",
   "metadata": {},
   "source": [
    "#### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b071553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(random_state=1)\n",
    "regressor.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379ac941",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c7255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators=5,random_state=1)\n",
    "regressor.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc68606",
   "metadata": {},
   "source": [
    "#### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde5e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel='rbf')\n",
    "regressor.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee953bc3",
   "metadata": {},
   "source": [
    "### Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2509b434",
   "metadata": {},
   "source": [
    "#### Dec. Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3520397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion='gini',random_state=1)\n",
    "classifier = DecisionTreeClassifier(criterion='entropy',random_state=1)\n",
    "classifier = DecisionTreeClassifier(criterion='log_loss',random_state=1)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80be6417",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0c6c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=100,criterion='gini',random_state=1)\n",
    "classifier = RandomForestClassifier(n_estimators=100,criterion='entropy',random_state=1)\n",
    "classifier = RandomForestClassifier(n_estimators=100,criterion='log_loss',random_state=1)\n",
    "classifier.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1273085",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93cec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914a6963",
   "metadata": {},
   "source": [
    "#### KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b0ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=10,metric='minkowski')\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca31fcc",
   "metadata": {},
   "source": [
    "#### Naive Bayes(Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6560b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b98195e",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc1fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='linear',random_state=1)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e75edd",
   "metadata": {},
   "source": [
    "#### Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeda01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='rbf',random_state=1)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f9d0c1",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e1072e",
   "metadata": {},
   "source": [
    "#### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb8de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding optimal number of Dendrograms\n",
    "import scipy.cluster.hierarchy as sch\n",
    "dendogram = sch.dendrogram(sch.linkage(x,method='ward'))\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Costumers')\n",
    "plt.ylabel('Euclidean Distances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e9c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the Hierarchical Clustering \n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster = AgglomerativeClustering(n_clusters=3,affinity='euclidean',linkage='ward')\n",
    "y_hc = cluster.fit_predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d8fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisin the Clusters\n",
    "plt.title('')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.scatter(x[y_hc==0,0],x[y_hc==0,1],s=100,c='red',label='Cluester 1')\n",
    "plt.scatter(x[y_hc==1,0],x[y_hc==1,1],s=100,c='blue',label='Cluester 2')\n",
    "plt.scatter(x[y_hc==2,0],x[y_hc==2,1],s=100,c='green',label='Cluester 3')\n",
    "plt.scatter(x[y_hc==3,0],x[y_hc==3,1],s=100,c='yellow',label='Cluester 4')\n",
    "plt.scatter(x[y_hc==4,0],x[y_hc==4,1],s=100,c='cyan',label='Cluester 5')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9ca35c",
   "metadata": {},
   "source": [
    "#### K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40941771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding optimal number of cluster with Elbow Method\n",
    "from sklearn.cluster import KMeans\n",
    "wcss = []\n",
    "for i in range(1,11):\n",
    "    kmeans = KMeans(n_clusters=i,init='k-means++',random_state=42,n_init=10)\n",
    "    kmeans.fit(x)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Cluster')\n",
    "plt.ylabel('WCSS Score')\n",
    "plt.plot(range(1,11),wcss,c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f3b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the K-Means Algorithm in Dataset\n",
    "kmeans = KMeans(n_clusters=5,n_init=10,init='k-means++',random_state=42)\n",
    "y_kmeans = kmeans.fit_predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e4ba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisin the Clusters\n",
    "plt.title('')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.scatter(x[y_kmeans==0,0],x[y_kmeans==0,1],s=100,c='red',label='Cluester 1')\n",
    "plt.scatter(x[y_kmeans==1,0],x[y_kmeans==1,1],s=100,c='blue',label='Cluester 2')\n",
    "plt.scatter(x[y_kmeans==2,0],x[y_kmeans==2,1],s=100,c='green',label='Cluester 3')\n",
    "plt.scatter(x[y_kmeans==3,0],x[y_kmeans==3,1],s=100,c='yellow',label='Cluester 4')\n",
    "plt.scatter(x[y_kmeans==4,0],x[y_kmeans==4,1],s=100,c='cyan',label='Cluester 5')\n",
    "plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=200,c='black',label='Center')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb74a379",
   "metadata": {},
   "source": [
    "### Association Rule Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3be91",
   "metadata": {},
   "source": [
    "#### Apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9955e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Dataset\n",
    "dataset = pd.read_csv('',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a5984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing\n",
    "transactions = []\n",
    "for i in range(0,7501): #7501-> Number of Transactions\n",
    "    transactions.append([str(dataset.values[i,j]) for j in range(0,20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08cb632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apriori Model\n",
    "from apyori import apriori\n",
    "rules = apriori(transactions = transactions,min_support = 0.003,min_confidence = 0.2,min_lift = 3,min_length = 2,max_lenght = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926f9e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising the results\n",
    "results = list(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ab162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Puting the results well organised into a Pandas DataFrame\n",
    "def inspect(results):\n",
    "    lhs         = [tuple(result[2][0][0])[0] for result in results]\n",
    "    rhs         = [tuple(result[2][0][1])[0] for result in results]\n",
    "    supports    = [result[1] for result in results]\n",
    "    confidences = [result[2][0][2] for result in results]\n",
    "    lifts       = [result[2][0][3] for result in results]\n",
    "    return list(zip(lhs, rhs, supports, confidences, lifts))\n",
    "resultsinDataFrame = pd.DataFrame(inspect(results), columns = ['Left Hand Side', 'Right Hand Side', 'Support', 'Confidence', 'Lift'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb60af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying sorted results\n",
    "resultsinDataFrame.nlargest(n = 10,columns = 'Lift')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b58f47",
   "metadata": {},
   "source": [
    "#### Eclat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c348d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Dataset\n",
    "dataset = pd.read_csv('',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2d7452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing\n",
    "transactions = []\n",
    "for i in range(0,7501): #7501-> Number of Transactions\n",
    "    transactions.append([str(dataset.values[i,j]) for j in range(0,20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888ffdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eclat Model\n",
    "from apyori import apriori\n",
    "rules = apriori(transactions = transactions,min_support = 0.003,min_confidence = 0.2,min_lift = 3,min_length = 2,max_lenght = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1facc909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising the results\n",
    "results = list(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9000c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Puting the results well organised into a Pandas DataFrame\n",
    "def inspect(results):\n",
    "    lhs         = [tuple(result[2][0][0])[0] for result in results]\n",
    "    rhs         = [tuple(result[2][0][1])[0] for result in results]\n",
    "    supports    = [result[1] for result in results]\n",
    "    return list(zip(lhs, rhs, supports))\n",
    "resultsinDataFrame = pd.DataFrame(inspect(results), columns = ['Product 1', 'Product 2', 'Support'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e7df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying sorted results\n",
    "resultsinDataFrame.nlargest(n = 10, columns = 'Support')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb943781",
   "metadata": {},
   "source": [
    "### Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2002a43c",
   "metadata": {},
   "source": [
    "#### UCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d5f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing UCB\n",
    "import math\n",
    "N = 10000\n",
    "d = 10\n",
    "ads_selected = []\n",
    "numbers_of_selections = [0] * d\n",
    "sums_of_rewards = [0] * d\n",
    "total_reward = 0\n",
    "for n in range(0, N):\n",
    "    ad = 0\n",
    "    max_upper_bound = 0\n",
    "    for i in range(0, d):\n",
    "        if (numbers_of_selections[i] > 0):\n",
    "            average_reward = sums_of_rewards[i] / numbers_of_selections[i]\n",
    "            delta_i = math.sqrt(3/2 * math.log(n + 1) / numbers_of_selections[i])\n",
    "            upper_bound = average_reward + delta_i\n",
    "        else:\n",
    "            upper_bound = 1e400\n",
    "        if upper_bound > max_upper_bound:\n",
    "            max_upper_bound = upper_bound\n",
    "            ad = i\n",
    "    ads_selected.append(ad)\n",
    "    numbers_of_selections[ad] = numbers_of_selections[ad] + 1\n",
    "    reward = dataset.values[n, ad]\n",
    "    sums_of_rewards[ad] = sums_of_rewards[ad] + reward\n",
    "    total_reward = total_reward + reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c469eac",
   "metadata": {},
   "source": [
    "#### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c439df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Dataset(If dataset is .tsv)\n",
    "dataset = pd.read_csv('',delimiter='\\t',quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627de7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the Texts\n",
    "import re \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus = []\n",
    "for i in range(0,1000):\n",
    "    review = re.sub('[^a-zA-Z]',' ',dataset['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    all_stopwords.remove('not')\n",
    "    review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a138a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Bag Of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "x = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54843ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose your classification algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac23020f",
   "metadata": {},
   "source": [
    "### Accuracy Score and Confusion Matris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d29b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Accuracy Score and Finding Confusion Matrix\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "y_pred = classifier.predict(x_test)\n",
    "print('Confusion Matrix: \\n {}'.format(confusion_matrix(y_test,y_pred)))\n",
    "print('Accuracy Score: {}'.format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674f354f",
   "metadata": {},
   "source": [
    "### Graph Sketching(General)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8fd060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sketching The Graph(Train Set)\n",
    "plt.title('')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.scatter(x,y,c='red')\n",
    "plt.plot(x_train,regressor.predict(x_train),c='blue')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
